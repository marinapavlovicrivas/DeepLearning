% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pretrain.R
\name{pretrain}
\alias{pretrain}
\alias{pretrain.DeepBeliefNet}
\alias{pretrain.RestrictedBolzmannMachine}
\title{Pre-trains the DeepBeliefNet or RestrictedBolzmannMachine. A contrastive divergence method is used to train each layer sequentially.}
\usage{
pretrain(x, data, ...)

\method{pretrain}{RestrictedBolzmannMachine}(x, data, miniters = 100,
  maxiters = floor(dim(data)[1]/batchsize), batchsize = 100, momentum = 0,
  penalization = c("l1", "l2", "none"), lambda = 0, lambda.b = lambda,
  lambda.c = lambda, lambda.W = lambda, epsilon = ifelse(x$output$type ==
  "gaussian", 0.001, 0.1), epsilon.b = epsilon, epsilon.c = epsilon,
  epsilon.W = epsilon, train.b = TRUE, train.c = TRUE,
  continue.function = continue.function.exponential,
  continue.function.frequency = 1000, continue.stop.limit = 30,
  diag = list(rate = diag.rate, data = diag.data, f = diag.function),
  diag.rate = c("none", "each", "accelerate"), diag.data = NULL,
  diag.function = NULL, n.proc = detectCores() - 1, ...)

\method{pretrain}{DeepBeliefNet}(x, data, miniters = 100,
  maxiters = floor(dim(data)[1]/batchsize), batchsize = 100,
  skip = numeric(0), momentum = 0, penalization = "l1", lambda = 2e-04,
  lambda.b = lambda, lambda.c = lambda, lambda.W = lambda,
  epsilon = 0.1, epsilon.b = epsilon, epsilon.c = epsilon,
  epsilon.W = epsilon, train.b = TRUE, train.c = length(x) - 1,
  continue.function = continue.function.exponential,
  continue.function.frequency = 100, continue.stop.limit = 3,
  diag = list(rate = diag.rate, data = diag.data, f = diag.function),
  diag.rate = c("none", "each", "accelerate"), diag.data = NULL,
  diag.function = NULL, n.proc = detectCores() - 1, ...)
}
\arguments{
\item{x}{the \code{\link{DeepBeliefNet}} or \code{\link{RestrictedBolzmannMachine}} object}

\item{data}{the dataset, either as matrix or data.frame. The number of columns must match the number of nodes of the network input}

\item{...}{ignored}

\item{miniters, maxiters}{minimum and maximum number of iterations to perform}

\item{batchsize}{the size of the minibatches}

\item{momentum}{the momentum, between 0 (no momentum) and 1 (no training). See the Momentums section below.}

\item{penalization}{the penalization mode. Either \dQuote{l1} (sparse), \dQuote{l2} (quadratic) or \dQuote{none}.}

\item{lambda}{penalty on large weights (weight-decay). Alternatively one can define \code{lambda.b}, \code{lambda.c} and \code{lambda.W} to constrain 
\code{b}s, \code{c}s and \code{W}s, respectively. Default: 0 = no penalization (equivalent to \code{penalization="none"}).}

\item{lambda.b, lambda.c, lambda.W}{separate penalty rates for \code{b}s, \code{c}s and \code{W}s. Take precedence over \code{lambda}.}

\item{epsilon}{learning rate. Alternatively one can define \code{epsilon.b}, \code{epsilon.c} and \code{epsilon.W} (see below)
to learn \code{b}s, \code{c}s and \code{W}s, respectively, at different speeds. Defaut: 0.1 (for layers where all inputs and outputs are binary or continuous)
 or 0.001 (for layers with gaussian input or output).}

\item{epsilon.b, epsilon.c, epsilon.W}{separate learning rates for \code{b}s, \code{c}s and \code{W}s. Take precedence over \code{epsilon}.}

\item{train.b, train.c}{whether (\code{\link{RestrictedBolzmannMachine}}) or on which layers (\code{\link{DeepBeliefNet}}) to update the \code{b}s and \code{c}s. For a \code{\link{RestrictedBolzmannMachine}}, must be a logical of length 1. For a \code{\link{DeepBeliefNet}} must be a logical (can be recycled) or numeric index of layers.}

\item{diag, diag.rate, diag.data, diag.function}{diagnmostic specifications. See details.}

\item{n.proc}{number of cores to be used for Eigen computations}

\item{skip}{numeric vector of the RestrictedBolzmannMachine of the DeepBeliefNet to be skipped.}
}
\value{
pre-trained object with the \code{pretrained} switch set to \code{TRUE}.
}
\section{Pretraining Layers of the Deep Belief Net with Different Parameters}{

It is possible to pre-train the layers of a DeepBeliefNet with different parameters. The following parameters can be supplied as vectors with length of the network - 1:
\code{batchsize}, \code{penalization}, \code{labmda}, \code{lambda.b}, \code{lambda.c}, \code{lambda.W}, 
\code{epsilon}, \code{epsilon.b}, \code{epsilon.c} and \code{epsilon.W}.
The values will be recycled if necessary (with essentially no warning if the lengths doesn't match). The special case of the \code{momentum} parameters is described below.
}

\section{Momentums}{

 The \code{momentum} parameter can take several length, and will be interpreted accordingly:
\itemize{
\item \code{1}: constant momentum
\item \code{2}: a gradient, will be interpreted as seq(momentum[1], momentum[2], length.out=maxiters)
\item \code{maxiter}: encodes the momentum per iteration
}
To specify different \code{momentum}s for the different layers of a DeepBeliefNet, they must be passed as a \code{\link{list}} of the same length than the number
of RestrictedBolzmannMachines to pretrain,
and they will be interpreted per layer as described above.
}

\section{Diagnostic specifications}{

The specifications can be passed directly in a list with elements \code{rate}, \code{data} and \code{f}, or separately with parameters \code{diag.rate}, \code{diag.data} and \code{diag.function}. The function must take the following parameters:
function(rbm, batch, data, iter, batchsize, maxiters, layer);
}

