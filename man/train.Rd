% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train.R
\name{train}
\alias{train}
\title{Fine-tunes the DeepBeliefNet}
\usage{
train(x, data, miniters = 100, maxiters = 1000, batchsize = 100,
  optim.control = list(), continue.function = continue.function.exponential,
  continue.function.frequency = 100, continue.stop.limit = 3,
  diag = list(rate = diag.rate, data = diag.data, f = diag.function),
  diag.rate = c("none", "each", "accelerate"), diag.data = NULL,
  diag.function = NULL, n.proc = detectCores() - 1, ...)
}
\arguments{
\item{x}{the DBN}

\item{data}{the training data}

\item{miniters, maxiters}{minimum and maximum number of iterations to perform}

\item{batchsize}{the size of the batches on which error & gradients are averaged}

\item{optim.control}{control arguments for the optim function that are not typically changed for normal operation. The parameters are:
maxit, type, trace, steplength, stepredn, acctol, reltest, abstol, intol, setstep. Their default values are defined in TrainParameters.h.}

\item{continue.function}{that can stop the training between miniters and maxiters if it returns \code{FALSE}. 
By default, \code{\link{continue.function.exponential}} will be used. An alternative is to use \code{\link{continue.function.always}} that will always return true and thus carry on with the training until maxiters is reached.
A user-supplied function must accept \code{(error, iter, batchsize)} as input and return a \code{\link{logical}} of length 1. The training is stopped when it returns \code{FALSE}.}

\item{continue.function.frequency}{the frequency at which continue.function will be assessed.}

\item{continue.stop.limit}{the number of consecutive times \code{continue.function} must return \code{FALSE} before the training is stopped. For example, \code{1} will stop as soon as \code{continue.function} returns \code{FALSE}, whereas \code{Inf} will ensure the result of \code{continue.function} is never enforced (but the function is still executed). The default is \code{3} so the training will continue until 3 consecutive calls of \code{continue.function} returned \code{FALSE}, giving more robustness to the decision.}

\item{diag, diag.rate, diag.data, diag.function}{diagnmostic specifications. See \code{\link{pretrain}} for more details}

\item{n.proc}{number of cores to be used for Eigen computations}

\item{...}{ignored}
}
\value{
the fine-tuned DBN
}
\description{
Performs fine-tuning on the DBN network with backpropagation.
}
\examples{
data(pretrained.mnist)
# Fine-tune the DBN with backpropagation
\dontrun{
trained.mnist <- train(unroll(pretrained.mnist), mnist$train$x, maxiters = 2000, batchsize = 1000,
                       optim.control = list(maxit = 10))
}
}

